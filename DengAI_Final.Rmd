---
title: "DengAI_FINAL"
author: "Oren Jalon"
date: "November 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#***SJ ANALYSIS***
#DATA PREPARATION
##LIBRARIES
```{r library, echo = TRUE}
library(tidyverse)
library(caret)
library(reshape2)
```
##IMPORT DATA
```{r inport, echo = TRUE, message = FALSE}

d_train <- read_csv("D:/Google Drive/RYERSON/CKME 136/DengAI/DATASET/dengue_features_train.csv")
d_labels <- read_csv("D:/Google Drive/RYERSON/CKME 136/DengAI/DATASET/dengue_labels_train.csv")
```
##MERGE TRAIN and LABELS
```{r add labels, echo=TRUE}
library(tidyverse)
df <- d_train %>%
  inner_join(d_labels, by = (c("city","year","weekofyear")))

```
##FILTER BY CITY
```{r sj & iq test, echo=TRUE}
library(tidyverse)

#splitting by city and dropping week of year
sj <- df %>%
  filter (city == "sj") 

iq <- df %>%
  filter (city == "iq")

```
#PREPROCESSING
##TRAINING AND TEST SETS(VALIDATION)
```{r preprocessing, echo = TRUE}

# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(sj$total_cases, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
trainData <- sj[trainRowNumbers,]

# Step 3: Create the test dataset
testData <- sj[-trainRowNumbers,]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

rm(iq, sj, df, trainRowNumbers)

```
##MISSING VALUES
```{r missing, echo = TRUE}
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData[,5:25], method='knnImpute')
preProcess_missingdata_model

# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnInpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)


```
##CORRELATION
```{r corr, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.2,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)


```


##NORMALIZE DATA
```{r standardize, echo = TRUE}
preProcess_range_model <- preProcess(trainData[,5:25], method=c("range"))
trainData <- predict(preProcess_range_model, newdata = trainData)

# Append the Y variable
trainData$total_cases <- y

apply(trainData[, 2:25], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})

rm(preProcess_range_model)
```
#PREPARE VALIDATION DATASET
```{r prepare test, echo = TRUE}
# Step 1: Impute missing values 
testData3 <- predict(preProcess_missingdata_model, testData)  
anyNA(testData3)

# Step 3: Transform the features to range between 0 and 1
preProcess_range_model <- preProcess(testData3[,5:25], method=c("range"))
testData4 <- predict(preProcess_range_model, newdata = testData3)

# Append the Y variable
testData4$total_cases <- testData$total_cases

# View
head(testData4[, 1:25])
summary(testData4)

rm(testData3, preProcess_missingdata_model, preProcess_range_model, x, y)
```
#TRAINING AND TUNING
##BASELINE 1
The baseline model shifts the total_cases down by one so that the values fall down to the next week.  The difference between the orignal and the shifted values are taken and the RMSE is used as the metric to measure performance.
```{r baseline 1,  echo = TRUE}
#create a new data frame from the original dataframe
trainData.shift <- trainData

#Make a copy of the total_cases variable
trainData.shift$total_cases2 <- trainData$total_cases

#shift the values down by one
trainData.shift['total_cases2'] <- c(NA, head(trainData.shift['total_cases2'], dim(trainData.shift)[1] - 1)[[1]])

#replace the first NA with zero
trainData.shift$total_cases2[1] <- 0

#take the difference between total_cases and total_cases2
trainData.shift$diff <- trainData.shift$total_cases2 - trainData.shift$total_cases

# Evaluate RMSE and MAE on the validation data
rmse.sj.baseline1 <- sqrt(mean((trainData.shift$diff)^2))
rmse.sj.baseline1

mae.sj.baseline1 <- mean(abs(trainData.shift$diff))
mae.sj.baseline1



```
##BASELINE 2
```{r baseline 2,  echo = TRUE}
# Baseline model - predict the mean of the training data
trainData.mean <- mean(trainData$total_cases)
 
# Evaluate RMSE and MAE on the validation data
rmse.sj.baseline2 <- sqrt(mean((trainData.mean-testData4$total_cases)^2))
rmse.sj.baseline2

mae.sj.baseline2 <- mean(abs(trainData.mean-testData4$total_cases))
mae.sj.baseline2
```
#PREDICTIVE MODELS
##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to total_cases
```{r ensemble corr_tc, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ reanalysis_specific_humidity_g_per_kg +
station_max_temp_c +
reanalysis_dew_point_temp_k +
station_avg_temp_c +
reanalysis_max_air_temp_k, 
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##GRAPH for CORR: ACTUAL VS PREDICTED
```{r graph corr, echo = TRUE}
#Plot the prediction for RF
df_predict_rf <- data.frame('prediction' = predict_rf,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_rf <- melt(df_predict_rf, id.vars = 'time')

ggplot(df_predict_rf, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('rf: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for xgbDART
df_predict_xgbDART <- data.frame('prediction' = predict_xgbDART,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_xgbDART <- melt(df_predict_xgbDART, id.vars = 'time')

ggplot(df_predict_xgbDART, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('xgbDART: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for svmRadial
df_predict_svmRadial <- data.frame('prediction' = predict_svmRadial,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_svmRadial <- melt(df_predict_svmRadial, id.vars = 'time')

ggplot(df_predict_svmRadial, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('svmRadial: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for KNN
df_predict_knn <- data.frame('prediction' = predict_knn,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_knn <- melt(df_predict_knn, id.vars = 'time')

ggplot(df_predict_knn, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('knn: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for Earth
df_predict_earth <- data.frame('prediction' = predict_earth,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_earth <- melt(df_predict_earth, id.vars = 'time')

ggplot(df_predict_earth, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('EARTH: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for svmLinear
df_predict_svmLinear <- data.frame('prediction' = predict_svmLinear,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_svmLinear <- melt(df_predict_svmLinear, id.vars = 'time')

ggplot(df_predict_svmLinear, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('svmLinear: Dengue predicted Cases vs. Actual Cases (City: SJ) ')
```

##COMBINED MODELS
```{r combined, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))

```
##GRAPH for COMBINED: ACTUAL VS PREDICTED
```{r graph combined, echo = TRUE}
#Plot the prediction for stack.corr
df_predict_stack.corr <- data.frame('prediction' = stack_predicteds.corr,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_stack.corr <- melt(df_predict_stack.corr, id.vars = 'time')

ggplot(df_predict_stack.corr, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('stack.corr: Dengue predicted Cases vs. Actual Cases (City: SJ) ')
```
#CREATE COPY OF THE trainData DATAFRAME
```{r copy trainData, echo=TRUE}
trainData2 <- trainData
```
#LAG MODELS - WEEK 1
##LEAD THE TOTAL CASES
```{r lead w1, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 1))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w1, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w1, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w1, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w1, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 2
##LEAD THE TOTAL CASES
```{r lead w2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 2))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 3
##LEAD THE TOTAL CASES
```{r lead w3, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 3))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w3, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w3, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w3, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w3, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 4
##LEAD THE TOTAL CASES
```{r lead w4, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 4))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w4, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w4, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w4, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w4, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 5
##LEAD THE TOTAL CASES
```{r lead w5, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 5))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w5, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w5, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w5, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w5, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 6
##LEAD THE TOTAL CASES
```{r lead w6, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 6))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w6, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w6, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w6, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w6, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 7
##LEAD THE TOTAL CASES
```{r lead w7, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 7))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w7, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w7, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w7, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.sj.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.sj.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.sj.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.sj.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.sj.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.sj.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.sj.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.sj.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.sj.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.sj.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.sj.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.sj.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.sj.earth
performetrics[2,2] <- rmse.sj.rf
performetrics[3,2] <- rmse.sj.xgbDART
performetrics[4,2] <- rmse.sj.svmRadial
performetrics[5,2] <- rmse.sj.knn
performetrics[6,2] <- rmse.sj.svmLinear

performetrics[1,3] <- mae.sj.earth 
performetrics[2,3] <- mae.sj.rf  
performetrics[3,3] <- mae.sj.xgbDART  
performetrics[4,3] <- mae.sj.svmRadial  
performetrics[5,3] <- mae.sj.knn  
performetrics[6,3] <- mae.sj.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w7, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.sj.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.sj.stack.corr:", RMSE.sj.stack.corr, sep=" "))

MAE.sj.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.sj.stack.corr:", MAE.sj.stack.corr, sep = " "))
```
#REMOVE ALL VARIABLES FOR IQ PREPARATION
```{r remove, echo=TRUE}
rm(list=ls())
```
#***IQ ANALYSIS***
#DATA PREPARATION
##LIBRARIES
```{r library2, echo = TRUE}
library(tidyverse)
library(caret)
library(reshape2)
```
##IMPORT DATA
```{r inport2, echo = TRUE, message = FALSE}

d_train <- read_csv("D:/Google Drive/RYERSON/CKME 136/DengAI/DATASET/dengue_features_train.csv")
d_labels <- read_csv("D:/Google Drive/RYERSON/CKME 136/DengAI/DATASET/dengue_labels_train.csv")
```
##MERGE TRAIN and LABELS
```{r add labels2, echo=TRUE}
library(tidyverse)
df <- d_train %>%
  inner_join(d_labels, by = (c("city","year","weekofyear")))

```
##FILTER BY CITY
```{r sj & iq test2, echo=TRUE}
library(tidyverse)

#splitting by city and dropping week of year
sj <- df %>%
  filter (city == "sj") 

iq <- df %>%
  filter (city == "iq")

```

#PREPROCESSING
##TRAINING AND TEST SETS(VALIDATION)
```{r preprocessing2, echo = TRUE}

# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(iq$total_cases, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
trainData <- iq[trainRowNumbers,]

# Step 3: Create the test dataset
testData <- iq[-trainRowNumbers,]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

rm(iq, iq, df, trainRowNumbers)

```
##MISSING VALUES
```{r missing2, echo = TRUE}
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData[,5:25], method='knnImpute')
preProcess_missingdata_model

# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnInpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)


```
##CORRELATION
```{r corr2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.2,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)


```


##NORMALIZE DATA
```{r standardize2, echo = TRUE}
preProcess_range_model <- preProcess(trainData[,5:25], method=c("range"))
trainData <- predict(preProcess_range_model, newdata = trainData)

# Append the Y variable
trainData$total_cases <- y

apply(trainData[, 2:25], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})

rm(preProcess_range_model)
```
#PREPARE VALIDATION DATASET
```{r prepare test2, echo = TRUE}
# Step 1: Impute missing values 
testData3 <- predict(preProcess_missingdata_model, testData)  
anyNA(testData3)

# Step 3: Transform the features to range between 0 and 1
preProcess_range_model <- preProcess(testData3[,5:25], method=c("range"))
testData4 <- predict(preProcess_range_model, newdata = testData3)

# Append the Y variable
testData4$total_cases <- testData$total_cases

# View
head(testData4[, 1:25])
summary(testData4)

rm(testData3, preProcess_missingdata_model, preProcess_range_model, x, y)
```
#TRAINING AND TUNING
##BASELINE 1
The baseline model shifts the total_cases down by one so that the values fall down to the next week.  The difference between the orignal and the shifted values are taken and the RMSE is used as the metric to measure performance.
```{r baseline 1 2,  echo = TRUE}
#create a new data frame from the original dataframe
trainData.shift <- trainData

#Make a copy of the total_cases variable
trainData.shift$total_cases2 <- trainData$total_cases

#shift the values down by one
trainData.shift['total_cases2'] <- c(NA, head(trainData.shift['total_cases2'], dim(trainData.shift)[1] - 1)[[1]])

#replace the first NA with zero
trainData.shift$total_cases2[1] <- 0

#take the difference between total_cases and total_cases2
trainData.shift$diff <- trainData.shift$total_cases2 - trainData.shift$total_cases

# Evaluate RMSE and MAE on the validation data
rmse.iq.baseline1 <- sqrt(mean((trainData.shift$diff)^2))
rmse.iq.baseline1

mae.iq.baseline1 <- mean(abs(trainData.shift$diff))
mae.iq.baseline1



```
##BASELINE 2
```{r baseline 2 2,  echo = TRUE}
# Baseline model - predict the mean of the training data
trainData.mean <- mean(trainData$total_cases)
 
# Evaluate RMSE and MAE on the validation data
rmse.iq.baseline2 <- sqrt(mean((trainData.mean-testData4$total_cases)^2))
rmse.iq.baseline2

mae.iq.baseline2 <- mean(abs(trainData.mean-testData4$total_cases))
mae.iq.baseline2
```
#PREDICTIVE MODELS
##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ reanalysis_specific_humidity_g_per_kg +
station_max_temp_c +
reanalysis_dew_point_temp_k +
station_avg_temp_c +
reanalysis_max_air_temp_k, 
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##GRAPH for CORR: ACTUAL VS PREDICTED
```{r graph corr2, echo = TRUE}
#Plot the prediction for RF
df_predict_rf <- data.frame('prediction' = predict_rf,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_rf <- melt(df_predict_rf, id.vars = 'time')

ggplot(df_predict_rf, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('rf: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for xgbDART
df_predict_xgbDART <- data.frame('prediction' = predict_xgbDART,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_xgbDART <- melt(df_predict_xgbDART, id.vars = 'time')

ggplot(df_predict_xgbDART, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('xgbDART: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for svmRadial
df_predict_svmRadial <- data.frame('prediction' = predict_svmRadial,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_svmRadial <- melt(df_predict_svmRadial, id.vars = 'time')

ggplot(df_predict_svmRadial, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('svmRadial: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for KNN
df_predict_knn <- data.frame('prediction' = predict_knn,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_knn <- melt(df_predict_knn, id.vars = 'time')

ggplot(df_predict_knn, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('knn: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for Earth
df_predict_earth <- data.frame('prediction' = predict_earth,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_earth <- melt(df_predict_earth, id.vars = 'time')

ggplot(df_predict_earth, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('EARTH: Dengue predicted Cases vs. Actual Cases (City: SJ) ')

#Plot the prediction for svmLinear
df_predict_svmLinear <- data.frame('prediction' = predict_svmLinear,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_svmLinear <- melt(df_predict_svmLinear, id.vars = 'time')

ggplot(df_predict_svmLinear, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('svmLinear: Dengue predicted Cases vs. Actual Cases (City: SJ) ')
```

##COMBINED MODELS
```{r combined2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))

```
##GRAPH for COMBINED: ACTUAL VS PREDICTED
```{r graph combined2, echo = TRUE}
#Plot the prediction for stack.corr
df_predict_stack.corr <- data.frame('prediction' = stack_predicteds.corr,
                                   'actual' = testData4$total_cases,
                                   'time' = testData4$week_start_date)

df_predict_stack.corr <- melt(df_predict_stack.corr, id.vars = 'time')

ggplot(df_predict_stack.corr, aes(x = time, y = value, color = variable)) +
  geom_line() +
  ggtitle('stack.corr: Dengue predicted Cases vs. Actual Cases (City: SJ) ')
```
#CREATE COPY OF THE trainData DATAFRAME
```{r copy trainData2, echo=TRUE}
trainData2 <- trainData
```
#LAG MODELS - WEEK 1
##LEAD THE TOTAL CASES
```{r lead w1 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 1))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w1 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w1 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w1 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w1 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 2
##LEAD THE TOTAL CASES
```{r lead w2 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 2))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w2 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w2 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w2 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w2 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 3
##LEAD THE TOTAL CASES
```{r lead w3 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 3))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w3 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w3 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w3 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w3 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 4
##LEAD THE TOTAL CASES
```{r lead w4 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 4))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w4 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w4 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w4 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w4 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 5
##LEAD THE TOTAL CASES
```{r lead w5 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 5))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w5 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w5 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w5 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w5 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 6
##LEAD THE TOTAL CASES
```{r lead w6 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 6))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w6 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w6 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w6 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w6 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#LAG MODELS - WEEK 7
##LEAD THE TOTAL CASES
```{r lead w7 2, echo=TRUE}


trainData <- trainData2 %>%
  arrange(year, weekofyear) %>%
  mutate(total_cases = lead(total_cases, 7))

#drop rows where total_cases == NA

trainData <- trainData[!is.na(trainData$total_cases),]

# Store X and Y for later use.
x = trainData[, 1:24]
y = trainData$total_cases

```
##CORRELATION
```{r corr w7 2, echo = TRUE}
library(tidyverse)
library(corrplot)
library(RColorBrewer)
require(gridExtra)

trainData %>% 
  dplyr::select(-city, -year, -weekofyear, -week_start_date) %>%
  cor(use = 'pairwise.complete.obs') -> M1

corrplot(M1, type="lower", method="shade",
           col=brewer.pal(n=8, name="RdBu"),tl.cex=0.75, tl.col = "black", diag=FALSE, title = "SJ Corrplot", mar=c(0,0,1,0))

# see the correlations as barplot
sort(M1[21,-21]) %>%  
  as.data.frame %>% 
  `names<-`('correlation') %>%
  ggplot(aes(x = reorder(row.names(.), -correlation), y = correlation, fill = correlation)) + 
  geom_bar(stat='identity', colour = 'black') + scale_fill_continuous(guide = FALSE) + scale_y_continuous(limits =  c(-.4,.4)) +
  labs(title = 'San Jose\n Correlations', x = NULL, y = NULL) + coord_flip() -> cor1

# can use ncol(M1) instead of 21 to generalize the code
grid.arrange(cor1, nrow = 1)
```

##MULTIPLE METHODS:CORR-TOTAL_CASES
Reducing the number of features to only those that are most correlated to tota_cases
```{r ensemble corr_tc w7 2, echo = TRUE}
library(caret)
library(caretEnsemble)

#tuneGrid for the various models

grid_rf <- expand.grid(.mtry = c(1,2,3,4,5))

grid_svmRadial <- expand.grid(sigma = c(.01, .015, 0.2), C = c(0.75, 0.9, 1, 1.1, 1.25))

grid_svmLinear <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))


#Make an algorithm list for caretList
algorithmList <- c("xgbDART", "knn", "earth")


# Stacking Algorithms - Run multiple algos in one call.
trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

set.seed(100)

models.corr <- caretList(total_cases ~ 
                           reanalysis_specific_humidity_g_per_kg +
reanalysis_dew_point_temp_k +
reanalysis_min_air_temp_k +
station_min_temp_c +
reanalysis_relative_humidity_percent,
                    data=trainData[,5:25], 
                    trControl=trainControl,
                    methodList=algorithmList,
                    tuneList=list(
                      rf=caretModelSpec(method="rf", tuneGrid=grid_rf),
                      svmLinear=caretModelSpec(method="svmLinear", tuneGrid=grid_svmLinear), 
                      svmRadial=caretModelSpec(method="svmRadial", tuneGrid=grid_svmRadial)))

results.corr <- resamples(models.corr)

summary(results.corr)

# Box plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results.corr, scales=scales)
dotplot(results.corr)

# correlation between results
modelCor(results.corr)
```

##MAE and RMSE for CORR-TC MODELS
```{r MAE RMSE CORR_TC w7 2, echo = TRUE}
# Step 3: Predict on testData and Compute the confusion matrix
predict_earth <- predict(models.corr$earth, testData4)
predict_rf <- predict(models.corr$rf, testData4)
predict_xgbDART <- predict(models.corr$xgbDART, testData4)
predict_svmRadial <- predict(models.corr$svmRadial, testData4)
predict_knn <- predict(models.corr$knn, testData4)
predict_svmLinear <- predict(models.corr$svmLinear, testData4)

# Evaluate RMSE and MAE on the test data
rmse.iq.earth <- sqrt(mean((predict_earth-testData4$total_cases)^2))
rmse.iq.rf <- sqrt(mean((predict_rf-testData4$total_cases)^2))
rmse.iq.xgbDART <- sqrt(mean((predict_xgbDART-testData4$total_cases)^2))
rmse.iq.svmRadial <- sqrt(mean((predict_svmRadial-testData4$total_cases)^2))
rmse.iq.svmLinear <- sqrt(mean((predict_svmLinear-testData4$total_cases)^2))

rmse.iq.knn <- sqrt(mean((predict_knn-testData4$total_cases)^2))

mae.iq.earth <- mean(abs(predict_earth-testData4$total_cases))
mae.iq.rf <- mean(abs(predict_rf-testData4$total_cases))
mae.iq.xgbDART <- mean(abs(predict_xgbDART-testData4$total_cases))
mae.iq.svmRadial <- mean(abs(predict_svmRadial-testData4$total_cases))
mae.iq.svmLinear <- mean(abs(predict_svmLinear-testData4$total_cases))
mae.iq.knn <- mean(abs(predict_knn-testData4$total_cases))

#Build a dataframe to put the MAE and RMSE
performetrics <- data.frame()


methods <- c("earth", "rf", "xgbDART", "svmRadial", "knn", "svmLinear")



performetrics[1,1] <- methods[1]
performetrics[2,1] <- methods[2]
performetrics[3,1] <- methods[3]
performetrics[4,1] <- methods[4]
performetrics[5,1] <- methods[5]
performetrics[6,1] <- methods[6]


performetrics[1,2] <- rmse.iq.earth
performetrics[2,2] <- rmse.iq.rf
performetrics[3,2] <- rmse.iq.xgbDART
performetrics[4,2] <- rmse.iq.svmRadial
performetrics[5,2] <- rmse.iq.knn
performetrics[6,2] <- rmse.iq.svmLinear

performetrics[1,3] <- mae.iq.earth 
performetrics[2,3] <- mae.iq.rf  
performetrics[3,3] <- mae.iq.xgbDART  
performetrics[4,3] <- mae.iq.svmRadial  
performetrics[5,3] <- mae.iq.knn  
performetrics[6,3] <- mae.iq.svmLinear

colnames(performetrics)[1]<- "Method"
colnames(performetrics)[2]<- "RMSE"
colnames(performetrics)[3]<- "MAE"


performetrics

```

##COMBINED MODELS
```{r combined w7 2, echo = TRUE}
# Create the trainControl
set.seed(100)
library(caret)
library(caretEnsemble)
stackControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3,
                             savePredictions="final",
                             index=createFolds(trainData$total_cases, 5))

# Ensemble the predictions of `models` to form a new combined prediction based on glm
stack.corr <- caretStack(models.corr, method="glm", trControl=stackControl)

print(stack.corr)

# Predict on testData
stack_predicteds.corr <- predict(stack.corr, newdata=testData4[,5:25])

# CORR Evaluate RMSE and MAE on the validation data
RMSE.iq.stack.corr <- sqrt(mean((stack_predicteds.corr - testData4$total_cases)^2))
print(paste("RMSE.iq.stack.corr:", RMSE.iq.stack.corr, sep=" "))

MAE.iq.stack.corr <- mean(abs(stack_predicteds.corr -testData4$total_cases))
print(paste("MAE.iq.stack.corr:", MAE.iq.stack.corr, sep = " "))
```
#REMOVE ALL VARIABLES FOR IQ PREPARATION
```{r remove 2, echo=TRUE}
rm(list=ls())
```


